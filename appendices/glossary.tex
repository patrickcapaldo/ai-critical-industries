\chapter{Glossary}
\label{chap:glossary}

This glossary provides definitions for key terms and concepts related to Artificial Intelligence (AI) and its application within critical industries. Understanding these terms is essential for navigating the complex landscape of AI adoption, governance, and impact in sectors vital to societal function and security.

\begin{description}
    \item[Accountability] The principle that individuals or organizations are responsible for the actions and impacts of AI systems, with mechanisms for redress when AI causes harm.
    \item[Adversarial AI] A field of study that focuses on the vulnerabilities of AI models to malicious inputs (adversarial examples) and the development of techniques to make AI systems more robust against such attacks.
    \item[Adversarial Attack] Maliciously crafted inputs designed to trick AI models into making incorrect predictions or decisions, often imperceptible to humans.
    \item[Adversarial Testing] A rigorous testing methodology that involves intentionally introducing perturbed or malicious inputs to an AI system to evaluate its robustness and identify vulnerabilities.
    \item[Algorithm] A set of rules or instructions that a computer follows to solve a problem or perform a task. In AI, algorithms are used to process data, learn patterns, and make predictions or decisions.
    \item[Algorithmic Trading] The use of computer programs to execute trades at high speed and volume, often based on complex algorithms that analyze market data and identify trading opportunities.
    \item[Anomaly Detection] The process of identifying rare items, events, or observations that deviate significantly from the majority of the data, often indicating a problem or unusual activity.
    \item[Artificial General Intelligence (AGI)] A hypothetical type of AI that possesses human-like cognitive abilities and the capacity to understand, learn, and apply knowledge across a wide range of tasks, not currently in existence.
    \item[Artificial Intelligence (AI)] The simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction.
    \item[Artificial Narrow Intelligence (ANI)] Also known as "weak AI," ANI is designed to perform specific, well-defined tasks. This is the type of AI currently deployed in various industries.
    \item[Augmentation] In the context of AI and work, refers to AI enhancing human intelligence and capabilities, allowing individuals to focus on higher-order tasks while AI handles routine activities.
    \item[Automation] The use of technology to perform tasks with minimal human intervention, often replacing manual labor or repetitive processes.
    \item[Bias (in AI)] Systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others. Bias can originate from biased training data, algorithmic design, or the way AI systems are used.
    \item[Black Box Problem] The difficulty in understanding how complex AI models, particularly deep learning models, arrive at their decisions, making their internal workings opaque to humans.
    \item[Computer Vision] A field of AI that enables computers to "see" and interpret visual information from the world, such as images and videos. Applications in critical industries include surveillance, quality control, and autonomous systems.
    \item[Concept Drift] A phenomenon in machine learning where the relationship between the input data and the target variable changes over time, requiring models to be retrained or adapted.
    \item[Convolutional Neural Networks (CNNs)] A specialized type of deep learning neural network particularly effective for image and video analysis, widely used in tasks like visual inspection and object detection.
    \item[Critical Infrastructure] Systems and assets, whether physical or virtual, so vital to a nation that the incapacity or destruction of such systems and assets would have a debilitating impact on security, national economic security, national public health or safety, or any combination of those matters.
    \item[Cybersecurity] The practice of protecting systems, networks, and programs from digital attacks. In the context of AI, it involves securing AI models, data, and infrastructure from malicious actors.
    \item[Cyber-Physical Systems (CPS)] Systems that integrate computation, networking, and physical processes. They are often used in critical infrastructure and can be enhanced or controlled by AI.
    \item[Data Bias] Systematic errors or prejudices in a dataset that can lead to unfair or inaccurate outcomes when used to train AI models.
    \item[Data Drift] A change in the distribution of input data over time, which can cause a deployed AI model's performance to degrade.
    \item[Data Governance] The overall management of the availability, usability, integrity, and security of data used in an enterprise. Effective data governance is crucial for reliable and ethical AI systems.
    \item[Data Integrity] The accuracy, consistency, and reliability of data over its lifecycle. Maintaining data integrity is crucial for trustworthy AI.
    \item[Data Lifecycle] The sequence of stages that data goes through from its initial generation or collection to its eventual archival or deletion, including collection, preparation, storage, analysis, and monitoring.
    \item[Data Poisoning] A type of adversarial attack where malicious data is intentionally introduced into an AI model's training dataset to corrupt its learning process and cause it to make incorrect predictions.
    \item[Data Privacy] The protection of sensitive personal information from unauthorized access, use, or disclosure, especially important given AI's reliance on vast datasets.
    \item[Deep Learning (DL)] A specialized subset of Machine Learning that uses multi-layered neural networks to learn from vast amounts of data. Deep learning models are particularly effective for tasks such as image recognition, natural language processing, and complex pattern detection.
    \item[Digital Transformation] The fundamental integration of digital technology into all areas of a business, fundamentally changing how it operates and delivers value. AI adoption is a significant component of this.
    \item[Digital Twin] A virtual representation of a physical object or system. Digital twins are used in critical industries for monitoring, analysis, and optimization, often incorporating AI for predictive capabilities.
    \item[Edge AI] The deployment of AI algorithms directly on edge devices (e.g., sensors, cameras, industrial equipment) rather than in a centralized cloud. This reduces latency and bandwidth requirements, crucial for real-time critical operations.
    \item[Ethical AI] The development and deployment of AI systems in a manner that aligns with human values, promotes fairness, ensures transparency, and respects privacy and human rights.
    \item[EU AI Act] A pioneering legislative framework by the European Union that categorizes AI systems based on their risk level, imposing stricter requirements on high-risk applications and banning certain unacceptable uses.
    \item[Explainable AI (XAI)] An emerging field of AI that aims to make AI models more transparent and understandable to humans. XAI techniques help users comprehend why an AI system made a particular decision or prediction.
    \item[Fair Use (in IP)] A legal doctrine that permits limited use of copyrighted material without acquiring permission from the rights holders, often asserted in cases of AI model training on copyrighted data.
    \item[Green AI] Practices and methodologies aimed at reducing the environmental impact of AI development and deployment, focusing on energy efficiency, resource optimization, and sustainable infrastructure.
    \item[Human-AI Collaboration] A synergistic approach where humans and AI systems work together, leveraging each other's strengths to achieve better outcomes than either could alone.
    \item[Human-in-the-loop] A model of AI system design where human oversight and intervention are integrated into the decision-making process, especially for critical or uncertain situations.
    \item[Human Oversight] The principle that humans should retain ultimate control and responsibility over AI systems, particularly in critical applications, ensuring human values and judgment remain central.
    \item[Information Technology (IT)] The use of computers, storage, networking, and other physical devices, infrastructure, and processes to create, process, store, secure, and exchange all forms of electronic data.
    \item[Internet of Things (IoT)] A network of physical objects embedded with sensors, software, and other technologies for the purpose of connecting and exchanging data with other devices and systems over the internet.
    \item[Large Language Models (LLMs)] Advanced AI models trained on vast amounts of text data, capable of understanding, generating, and processing human language for a wide range of tasks.
    \item[Lethal Autonomous Weapon Systems (LAWS)] Weapon systems that can select and engage targets without human intervention. Their development raises significant ethical and strategic concerns.
    \item[Machine Learning (ML)] A subset of AI that enables systems to learn from data without being explicitly programmed. Instead of relying on predefined rules, ML algorithms identify patterns and relationships in data to make predictions or decisions.
    \item[Multimodal AI] AI systems capable of processing and understanding information from multiple modalities, such as text, images, video, and audio, simultaneously.
    \item[Natural Language Processing (NLP)] A branch of AI that enables computers to understand, interpret, and generate human language. NLP is used in critical industries for tasks like sentiment analysis, document processing, and intelligent assistants.
    \item[NIST AI Risk Management Framework (AI RMF)] A voluntary framework developed by the U.S. National Institute of Standards and Technology that provides structured guidance for identifying, assessing, and mitigating risks associated with AI systems.
    \item[Operational Technology (OT)] Hardware and software that detects or causes a change through the direct monitoring and/or control of physical devices, processes, and events in the enterprise. Often used in industrial control systems.
    \item[Organizational Change Management (OCM)] A structured approach to transitioning individuals, teams, and organizations from a current state to a desired future state, often used to facilitate the adoption of new technologies like AI.
    \item[Precision Agriculture] A farming management concept based on observing, measuring, and responding to inter and intra-field variability in crops. It leverages AI to optimize farming practices and resource use.
    \item[Predictive Maintenance] The use of data analytics and AI to predict when equipment failure might occur, allowing for proactive maintenance to prevent costly downtime.
    \item[Product Liability Directive (PLD)] A European Union directive that establishes strict liability for defective products, including those incorporating AI, making manufacturers liable for damages caused by their products regardless of fault.
    \item[Recurrent Neural Networks (RNNs)] A type of deep learning neural network designed to handle sequential data, making them suitable for natural language processing and time-series analysis.
    \item[Regulatory Sandbox] A framework set up by a regulator to allow small-scale, live testing of new products or services in a controlled environment under the regulator's supervision. This can be used for AI innovations in critical industries.
    \item[Reinforcement Learning] A type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a cumulative reward, often used for optimizing complex, dynamic systems.
    \item[Resilience (in Critical Industries)] The ability of critical infrastructure systems to withstand and recover from disruptions, including those caused by cyberattacks, natural disasters, or AI system failures.
    \item[Shadow AI] The use of unauthorized or unmonitored AI tools by employees within an organization, which can introduce significant risks, including data exposure and compliance violations.
    \item[Smart Grids] Modernized electricity networks that use information and communication technologies to gather information, such as data about the behaviors of suppliers and consumers, in an automated fashion to improve the efficiency, reliability, and sustainability of the production and distribution of electricity.
    \item[Smart Water Grids] Advanced water management systems that use sensors, data analytics, and AI to monitor, control, and optimize water distribution, leak detection, and overall water resource management.
    \item[Supervised Learning] A type of machine learning where the algorithm is trained on a labeled dataset (input-output pairs) to learn a mapping function that can predict the output for new, unseen data.
    \item[Systemic Risk] The risk of collapse of an entire system or market, as opposed to the failure of individual components. AI's interconnectedness in critical industries can introduce new systemic risks.
    \item[Transparency] The principle that the internal workings and decision-making processes of AI systems should be open and understandable, fostering trust and enabling accountability.
    \item[Unsupervised Learning] A type of machine learning where algorithms work with unlabeled data to identify hidden patterns, structures, or relationships within the data itself, often used for anomaly detection or clustering.
\end{description}